{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import glob\n",
    "from matplotlib import animation\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from itertools import combinations\n",
    "import scipy\n",
    "from scipy.stats import entropy\n",
    "from sklearn import manifold\n",
    "from adjustText import adjust_text\n",
    "from mpl_toolkits import mplot3d\n",
    "import networkx as nx\n",
    "import os.path as osp\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.style.use('seaborn-white')\n",
    "plt.style.use('seaborn')\n",
    "# for matplotlib xkcd I need to install new font without root, like this: \n",
    "#https://community.linuxmint.com/tutorial/view/29\n",
    "# and then ivalidate cache like this: \n",
    "#https://stackoverflow.com/questions/19663986/getting-xkcd-plots-using-matplotlib/22812176#22812176\n",
    "# or by deleting by: rm ~/.cache/matplotlib -r\n",
    "# the font ttf file must be in ~/.fonts/fonts/truetype/humor-sans directory\n",
    "\n",
    "# to recover from xkcd\n",
    "#mpl.rcParams.update(saved_state)\n",
    "\n",
    "# to save state and go to xkcd\n",
    "#saved_state = mpl.rcParams.copy()\n",
    "#plt.xkcd()\n",
    "conf = {\n",
    "    'font.size': 14.0,\n",
    "    'axes.grid': True,\n",
    "    'figure.titlesize': 'x-large',\n",
    "    'axes.titlesize': 'x-large',\n",
    "    'axes.labelsize': 'large',\n",
    "#    'xtick.labelsize': 'medium',\n",
    "#    'ytick.labelsize': 'medium',\n",
    "#    'legend.fontsize': 'medium',\n",
    "    'xtick.labelsize': 'large',\n",
    "    'ytick.labelsize': 'large',\n",
    "    'legend.fontsize': 'large',\n",
    "}\n",
    "\n",
    "plt.rcParams.update(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned data are good for user anylysis but not for anime analysis. For users, around 200k animelist records were discarded, over 30m records remainded.\n",
    "animes = pd.read_csv('anime_cleaned.csv')\n",
    "users = pd.read_csv('users_cleaned.csv')\n",
    "animelists = pd.read_csv('animelists_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['birth_date'] = pd.to_datetime(users['birth_date'])\n",
    "users['last_online'] = pd.to_datetime(users['last_online'])\n",
    "users['join_date'] = pd.to_datetime(users['join_date'])\n",
    "animelists['my_last_updated'] = pd.to_datetime(animelists['my_last_updated'])\n",
    "# renaming possibly array-like columns to end with -s\n",
    "animes = animes.rename(columns={'genre': 'genres', 'studio': 'studios'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting index for primary identifiers\n",
    "animes = animes.set_index('anime_id')\n",
    "users = users.set_index('username')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['age'] = 2018 - users['birth_date'].dt.year   # fix this to be more robust and precise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>title_synonyms</th>\n",
       "      <th>image_url</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>airing</th>\n",
       "      <th>...</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>related</th>\n",
       "      <th>producer</th>\n",
       "      <th>licensor</th>\n",
       "      <th>studios</th>\n",
       "      <th>genres</th>\n",
       "      <th>opening_theme</th>\n",
       "      <th>ending_theme</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>aired_from_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anime_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11013</th>\n",
       "      <td>Inu x Boku SS</td>\n",
       "      <td>Inu X Boku Secret Service</td>\n",
       "      <td>妖狐×僕SS</td>\n",
       "      <td>Youko x Boku SS</td>\n",
       "      <td>https://myanimelist.cdn-dena.com/images/anime/...</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manga</td>\n",
       "      <td>12</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Fridays at Unknown</td>\n",
       "      <td>{'Adaptation': [{'mal_id': 17207, 'type': 'man...</td>\n",
       "      <td>Aniplex, Square Enix, Mainichi Broadcasting Sy...</td>\n",
       "      <td>Sentai Filmworks</td>\n",
       "      <td>David Production</td>\n",
       "      <td>Comedy, Supernatural, Romance, Shounen</td>\n",
       "      <td>['\"Nirvana\" by MUCC']</td>\n",
       "      <td>['#1: \"Nirvana\" by MUCC (eps 1, 11-12)', '#2: ...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>Seto no Hanayome</td>\n",
       "      <td>My Bride is a Mermaid</td>\n",
       "      <td>瀬戸の花嫁</td>\n",
       "      <td>The Inland Sea Bride</td>\n",
       "      <td>https://myanimelist.cdn-dena.com/images/anime/...</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manga</td>\n",
       "      <td>26</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>{'Adaptation': [{'mal_id': 759, 'type': 'manga...</td>\n",
       "      <td>TV Tokyo, AIC, Square Enix, Sotsu</td>\n",
       "      <td>Funimation</td>\n",
       "      <td>Gonzo</td>\n",
       "      <td>Comedy, Parody, Romance, School, Shounen</td>\n",
       "      <td>['\"Romantic summer\" by SUN&amp;LUNAR']</td>\n",
       "      <td>['#1: \"Ashita e no Hikari (明日への光)\" by Asuka Hi...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>Shugo Chara!! Doki</td>\n",
       "      <td>Shugo Chara!! Doki</td>\n",
       "      <td>しゅごキャラ！！どきっ</td>\n",
       "      <td>Shugo Chara Ninenme, Shugo Chara! Second Year</td>\n",
       "      <td>https://myanimelist.cdn-dena.com/images/anime/...</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manga</td>\n",
       "      <td>51</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>{'Adaptation': [{'mal_id': 101, 'type': 'manga...</td>\n",
       "      <td>TV Tokyo, Sotsu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satelight</td>\n",
       "      <td>Comedy, Magic, School, Shoujo</td>\n",
       "      <td>['#1: \"Minna no Tamago (みんなのたまご)\" by Shugo Cha...</td>\n",
       "      <td>['#1: \"Rottara Rottara (ロッタラ ロッタラ)\" by Buono! ...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>Princess Tutu</td>\n",
       "      <td>Princess Tutu</td>\n",
       "      <td>プリンセスチュチュ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://myanimelist.cdn-dena.com/images/anime/...</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>38</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Fridays at Unknown</td>\n",
       "      <td>{'Adaptation': [{'mal_id': 1581, 'type': 'mang...</td>\n",
       "      <td>Memory-Tech, GANSIS, Marvelous AQL</td>\n",
       "      <td>ADV Films</td>\n",
       "      <td>Hal Film Maker</td>\n",
       "      <td>Comedy, Drama, Magic, Romance, Fantasy</td>\n",
       "      <td>['\"Morning Grace\" by Ritsuko Okazaki']</td>\n",
       "      <td>['\"Watashi No Ai Wa Chiisaikeredo\" by Ritsuko ...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12365</th>\n",
       "      <td>Bakuman. 3rd Season</td>\n",
       "      <td>Bakuman.</td>\n",
       "      <td>バクマン。</td>\n",
       "      <td>Bakuman Season 3</td>\n",
       "      <td>https://myanimelist.cdn-dena.com/images/anime/...</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manga</td>\n",
       "      <td>25</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>{'Adaptation': [{'mal_id': 9711, 'type': 'mang...</td>\n",
       "      <td>NHK, Shueisha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J.C.Staff</td>\n",
       "      <td>Comedy, Drama, Romance, Shounen</td>\n",
       "      <td>['#1: \"Moshimo no Hanashi (もしもの話)\" by nano.RIP...</td>\n",
       "      <td>['#1: \"Pride on Everyday\" by Sphere (eps 1-13)...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title              title_english title_japanese  \\\n",
       "anime_id                                                                  \n",
       "11013           Inu x Boku SS  Inu X Boku Secret Service         妖狐×僕SS   \n",
       "2104         Seto no Hanayome      My Bride is a Mermaid          瀬戸の花嫁   \n",
       "5262       Shugo Chara!! Doki         Shugo Chara!! Doki    しゅごキャラ！！どきっ   \n",
       "721             Princess Tutu              Princess Tutu      プリンセスチュチュ   \n",
       "12365     Bakuman. 3rd Season                   Bakuman.          バクマン。   \n",
       "\n",
       "                                         title_synonyms  \\\n",
       "anime_id                                                  \n",
       "11013                                   Youko x Boku SS   \n",
       "2104                               The Inland Sea Bride   \n",
       "5262      Shugo Chara Ninenme, Shugo Chara! Second Year   \n",
       "721                                                 NaN   \n",
       "12365                                  Bakuman Season 3   \n",
       "\n",
       "                                                  image_url type    source  \\\n",
       "anime_id                                                                     \n",
       "11013     https://myanimelist.cdn-dena.com/images/anime/...   TV     Manga   \n",
       "2104      https://myanimelist.cdn-dena.com/images/anime/...   TV     Manga   \n",
       "5262      https://myanimelist.cdn-dena.com/images/anime/...   TV     Manga   \n",
       "721       https://myanimelist.cdn-dena.com/images/anime/...   TV  Original   \n",
       "12365     https://myanimelist.cdn-dena.com/images/anime/...   TV     Manga   \n",
       "\n",
       "          episodes           status  airing  ...           broadcast  \\\n",
       "anime_id                                     ...                       \n",
       "11013           12  Finished Airing   False  ...  Fridays at Unknown   \n",
       "2104            26  Finished Airing   False  ...             Unknown   \n",
       "5262            51  Finished Airing   False  ...             Unknown   \n",
       "721             38  Finished Airing   False  ...  Fridays at Unknown   \n",
       "12365           25  Finished Airing   False  ...             Unknown   \n",
       "\n",
       "                                                    related  \\\n",
       "anime_id                                                      \n",
       "11013     {'Adaptation': [{'mal_id': 17207, 'type': 'man...   \n",
       "2104      {'Adaptation': [{'mal_id': 759, 'type': 'manga...   \n",
       "5262      {'Adaptation': [{'mal_id': 101, 'type': 'manga...   \n",
       "721       {'Adaptation': [{'mal_id': 1581, 'type': 'mang...   \n",
       "12365     {'Adaptation': [{'mal_id': 9711, 'type': 'mang...   \n",
       "\n",
       "                                                   producer          licensor  \\\n",
       "anime_id                                                                        \n",
       "11013     Aniplex, Square Enix, Mainichi Broadcasting Sy...  Sentai Filmworks   \n",
       "2104                      TV Tokyo, AIC, Square Enix, Sotsu        Funimation   \n",
       "5262                                        TV Tokyo, Sotsu               NaN   \n",
       "721                      Memory-Tech, GANSIS, Marvelous AQL         ADV Films   \n",
       "12365                                         NHK, Shueisha               NaN   \n",
       "\n",
       "                   studios                                    genres  \\\n",
       "anime_id                                                               \n",
       "11013     David Production    Comedy, Supernatural, Romance, Shounen   \n",
       "2104                 Gonzo  Comedy, Parody, Romance, School, Shounen   \n",
       "5262             Satelight             Comedy, Magic, School, Shoujo   \n",
       "721         Hal Film Maker    Comedy, Drama, Magic, Romance, Fantasy   \n",
       "12365            J.C.Staff           Comedy, Drama, Romance, Shounen   \n",
       "\n",
       "                                              opening_theme  \\\n",
       "anime_id                                                      \n",
       "11013                                 ['\"Nirvana\" by MUCC']   \n",
       "2104                     ['\"Romantic summer\" by SUN&LUNAR']   \n",
       "5262      ['#1: \"Minna no Tamago (みんなのたまご)\" by Shugo Cha...   \n",
       "721                  ['\"Morning Grace\" by Ritsuko Okazaki']   \n",
       "12365     ['#1: \"Moshimo no Hanashi (もしもの話)\" by nano.RIP...   \n",
       "\n",
       "                                               ending_theme  duration_min  \\\n",
       "anime_id                                                                    \n",
       "11013     ['#1: \"Nirvana\" by MUCC (eps 1, 11-12)', '#2: ...          24.0   \n",
       "2104      ['#1: \"Ashita e no Hikari (明日への光)\" by Asuka Hi...          24.0   \n",
       "5262      ['#1: \"Rottara Rottara (ロッタラ ロッタラ)\" by Buono! ...          24.0   \n",
       "721       ['\"Watashi No Ai Wa Chiisaikeredo\" by Ritsuko ...          16.0   \n",
       "12365     ['#1: \"Pride on Everyday\" by Sphere (eps 1-13)...          24.0   \n",
       "\n",
       "          aired_from_year  \n",
       "anime_id                   \n",
       "11013              2012.0  \n",
       "2104               2007.0  \n",
       "5262               2008.0  \n",
       "721                2002.0  \n",
       "12365              2012.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>21</td>\n",
       "      <td>586</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 10:52:53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-10 13:54:51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27 16:43:35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-03 10:53:57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>karthiga</td>\n",
       "      <td>178</td>\n",
       "      <td>26</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-27 15:59:13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   username  anime_id  my_watched_episodes my_start_date my_finish_date  \\\n",
       "0  karthiga        21                  586    0000-00-00     0000-00-00   \n",
       "1  karthiga        59                   26    0000-00-00     0000-00-00   \n",
       "2  karthiga        74                   26    0000-00-00     0000-00-00   \n",
       "3  karthiga       120                   26    0000-00-00     0000-00-00   \n",
       "4  karthiga       178                   26    0000-00-00     0000-00-00   \n",
       "\n",
       "   my_score  my_status  my_rewatching  my_rewatching_ep     my_last_updated  \\\n",
       "0         9          1            NaN                 0 2013-03-03 10:52:53   \n",
       "1         7          2            NaN                 0 2013-03-10 13:54:51   \n",
       "2         7          2            NaN                 0 2013-04-27 16:43:35   \n",
       "3         7          2            NaN                 0 2013-03-03 10:53:57   \n",
       "4         7          2            0.0                 0 2013-03-27 15:59:13   \n",
       "\n",
       "  my_tags  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animelists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_watching</th>\n",
       "      <th>user_completed</th>\n",
       "      <th>user_onhold</th>\n",
       "      <th>user_dropped</th>\n",
       "      <th>user_plantowatch</th>\n",
       "      <th>user_days_spent_watching</th>\n",
       "      <th>gender</th>\n",
       "      <th>location</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>access_rank</th>\n",
       "      <th>join_date</th>\n",
       "      <th>last_online</th>\n",
       "      <th>stats_mean_score</th>\n",
       "      <th>stats_rewatched</th>\n",
       "      <th>stats_episodes</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>karthiga</th>\n",
       "      <td>2255153</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.091667</td>\n",
       "      <td>Female</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>1990-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-03-03</td>\n",
       "      <td>2014-02-04 01:32:00</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3391</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Damonashu</th>\n",
       "      <td>37326</td>\n",
       "      <td>45</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>59</td>\n",
       "      <td>82.574306</td>\n",
       "      <td>Male</td>\n",
       "      <td>Detroit,Michigan</td>\n",
       "      <td>1991-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-02-13</td>\n",
       "      <td>2017-07-10 06:52:54</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4903</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bskai</th>\n",
       "      <td>228342</td>\n",
       "      <td>25</td>\n",
       "      <td>414</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>159.483333</td>\n",
       "      <td>Male</td>\n",
       "      <td>Nayarit, Mexico</td>\n",
       "      <td>1990-12-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-08-31</td>\n",
       "      <td>2014-05-12 16:35:00</td>\n",
       "      <td>8.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9701</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terune_uzumaki</th>\n",
       "      <td>327311</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.394444</td>\n",
       "      <td>Female</td>\n",
       "      <td>Malaysia, Kuantan</td>\n",
       "      <td>1998-08-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-05-10</td>\n",
       "      <td>2012-10-18 19:06:00</td>\n",
       "      <td>9.70</td>\n",
       "      <td>6.0</td>\n",
       "      <td>697</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bas_G</th>\n",
       "      <td>5015094</td>\n",
       "      <td>35</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>175</td>\n",
       "      <td>30.458333</td>\n",
       "      <td>Male</td>\n",
       "      <td>Nijmegen, Nederland</td>\n",
       "      <td>1999-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-26</td>\n",
       "      <td>2018-05-10 20:53:37</td>\n",
       "      <td>7.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1847</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user_id  user_watching  user_completed  user_onhold  \\\n",
       "username                                                              \n",
       "karthiga        2255153              3              49            1   \n",
       "Damonashu         37326             45             195           27   \n",
       "bskai            228342             25             414            2   \n",
       "terune_uzumaki   327311              5               5            0   \n",
       "Bas_G           5015094             35             114            6   \n",
       "\n",
       "                user_dropped  user_plantowatch  user_days_spent_watching  \\\n",
       "username                                                                   \n",
       "karthiga                   0                 0                 55.091667   \n",
       "Damonashu                 25                59                 82.574306   \n",
       "bskai                      5                11                159.483333   \n",
       "terune_uzumaki             0                 0                 11.394444   \n",
       "Bas_G                     20               175                 30.458333   \n",
       "\n",
       "                gender             location birth_date  access_rank  \\\n",
       "username                                                              \n",
       "karthiga        Female      Chennai, India  1990-04-29          NaN   \n",
       "Damonashu         Male     Detroit,Michigan 1991-08-01          NaN   \n",
       "bskai             Male      Nayarit, Mexico 1990-12-14          NaN   \n",
       "terune_uzumaki  Female    Malaysia, Kuantan 1998-08-24          NaN   \n",
       "Bas_G             Male  Nijmegen, Nederland 1999-10-24          NaN   \n",
       "\n",
       "                join_date         last_online  stats_mean_score  \\\n",
       "username                                                          \n",
       "karthiga       2013-03-03 2014-02-04 01:32:00              7.43   \n",
       "Damonashu      2008-02-13 2017-07-10 06:52:54              6.15   \n",
       "bskai          2009-08-31 2014-05-12 16:35:00              8.27   \n",
       "terune_uzumaki 2010-05-10 2012-10-18 19:06:00              9.70   \n",
       "Bas_G          2015-11-26 2018-05-10 20:53:37              7.86   \n",
       "\n",
       "                stats_rewatched  stats_episodes  age  \n",
       "username                                              \n",
       "karthiga                    0.0            3391   28  \n",
       "Damonashu                   6.0            4903   27  \n",
       "bskai                       1.0            9701   28  \n",
       "terune_uzumaki              6.0             697   20  \n",
       "Bas_G                       0.0            1847   19  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparison of all and active users\n",
    "Active users are users with some ratings in last 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-05-22 07:49:06')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# newest update date, reflects time of data gathering\n",
    "now = animelists['my_last_updated'].max()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "last_update = animelists.groupby('username')['my_last_updated'].max()\n",
    "is_active = last_update > (now - relativedelta(months=3))\n",
    "active_users = last_update[is_active].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(users['gender'].value_counts() / users['gender'].count()).sort_index().plot.bar(figsize=(16, 10), title='all vs. active users gender', color='blue', alpha=0.5, label='all users')\n",
    "(users.loc[active_users]['gender'].value_counts() / users.loc[active_users]['gender'].count()).sort_index().plot.bar(figsize=(16, 10), color='red', alpha=0.5, label='users rating in last 3 months')\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(users['age'].value_counts() / users['age'].count()).sort_index().plot.bar(figsize=(16, 10), title='all vs. active users age', color='blue', alpha=0.5, label='all users')\n",
    "(users.loc[active_users]['age'].value_counts() / users.loc[active_users]['age'].count()).sort_index().plot.bar(figsize=(16, 10), color='red', alpha=0.5, label='users rating in last 3 months')\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspecing seen animes per all genres by age, gender etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animes['genres'].fillna('', inplace=True)\n",
    "genres_arr = animes['genres'].str.replace(' ', '').str.split(',', expand=True).stack().reset_index(drop=True, level=1).to_frame(name='genre')\n",
    "genres_arr = genres_arr[genres_arr['genre'] != '']\n",
    "animes_genres = pd.merge(animes, genres_arr, how='inner', left_index=True, right_index=True)\n",
    "genres = genres_arr['genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fastest and safest option (having separate dataframe per each genre is better than one big dataframe)\n",
    "from joblib import Parallel, delayed\n",
    "# todo: rewrite all queries using animelists_genres to access dict\n",
    "def filter_by_genre(animelists, genre):\n",
    "    print(genre)\n",
    "    return genre, animelists[animelists.index.isin(genres_arr[genres_arr['genre'] == genre].index)]\n",
    "\n",
    "res_lists = Parallel(n_jobs=16, backend='threading')(delayed(filter_by_genre)(animelists, genre) for genre in genres_arr['genre'].unique())\n",
    "animelists_genres = {key: val for key, val in res_lists}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "animelists.iloc[0:5]['genres'].apply(lambda x: x.replace(' ', '').split(',')).apply(pd.Series).stack().to_frame(name='genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = pd.MultiIndex.from_tuples([(x[0], y) for i, x in enumerate(animelists.iloc[0:5][['anime_id', 'genres']].apply(lambda x: (x[0], x[1].replace(' ', '').split(',')), axis=1)) for y, _ in enumerate(x[1])])\n",
    "pd.Series([y for x in animelists.iloc[0:5]['genres'].apply(lambda x: x.replace(' ', '').split(',')) for y in x], index=indices).to_frame(name='genre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([(x[0], y) for i, x in enumerate(animelists.iloc[0:5][['anime_id', 'genres']].apply(lambda x: (x[0], x[1].replace(' ', '').split(',')), axis=1)) for y in x[1]], columns=['anime_id', 'genre'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantics of my_status column\n",
    "status = {\n",
    "    'watching': 1,\n",
    "    'completed': 2,\n",
    "    'on hold': 3,\n",
    "    'dropped': 4,\n",
    "    'plan to watch': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if osp.exists('users_calculated.csv'):\n",
    "    users = pd.read_csv('users_calculated.csv')\n",
    "    users = users.set_index('username')\n",
    "else:\n",
    "    # handcrafted features\n",
    "    genres_columns = ['completed_'+x for x in genres]\n",
    "    for genre_column, genre in zip(genres_columns, genres):\n",
    "        animelists_genre = animelists_genres[genre]\n",
    "        completed = animelists_genre['my_status'] == status['completed']\n",
    "        users[genre_column] = animelists_genre[completed].groupby('username')['genre'].count()\n",
    "    \n",
    "    genres_columns = ['dropped_'+x for x in genres]\n",
    "    for genre_column, genre in zip(genres_columns, genres):\n",
    "        animelists_genre = animelists_genres[genre]\n",
    "        dropped = animelists_genre['my_status'] == status['dropped']\n",
    "        users[genre_column] = animelists_genre[droppeed].groupby('username')['genre'].count()\n",
    "    \n",
    "    genres_columns = ['meanscore_'+x for x in genres]\n",
    "    for genre_column, genre in zip(genres_columns, genres):\n",
    "        animelists_genre = animelists_genres[genre]\n",
    "        rated = (animelists_genre['my_score'] != 0)\n",
    "        completed = animelists_genre['my_status'] == status['completed']\n",
    "        users[genre_column] = animelists_genre[completed & rated].groupby('username')['my_score'].mean()\n",
    "\n",
    "    # good score is 9 or higher\n",
    "    genres_columns = ['scoreabove8_'+x for x in genres]\n",
    "    for genre_column, genre in zip(genres_columns, genres):\n",
    "        animelists_genre = animelists_genres[genre]\n",
    "        completed = animelists_genres['my_status'] == status['completed']\n",
    "        rated = animelists_genres['my_score'] > 8\n",
    "        users[genre_column] = animelists_genre[completed & rated].groupby('username')['my_score'].count()\n",
    "\n",
    "    # score is 10\n",
    "    genres_columns = ['scoreabove9_'+x for x in genres]\n",
    "    for genre_column, genre in zip(genres_columns, genres):\n",
    "        animelists_genre = animelists_genres[genre]\n",
    "        completed = animelists_genres['my_status'] == status['completed']\n",
    "        rated = animelists_genres['my_score'] > 9\n",
    "        users[genre_column] = animelists_genre[completed & rated].groupby('username')['my_score'].count()\n",
    "    \n",
    "    completed = (animelists['my_status'] == status['completed'])\n",
    "    dropped = (animelists['my_status'] == status['dropped'])\n",
    "    rated = (animelists['my_score'] != 0)\n",
    "    users['all_completed'] = animelists[completed].groupby('username')['anime_id'].count()\n",
    "    users['all_dropped'] = animelists[dropped].groupby('username')['anime_id'].count()\n",
    "    users['all_meanscore'] = animelists[completed & rated].groupby('username')['my_score'].mean()\n",
    "    users['all_rated'] = animelists[completed & rated].groupby('username')['anime_id'].count()\n",
    "\n",
    "    users.reset_index().to_csv('users_calculated.csv', index=False, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing score distribution\n",
    "scores = animelists[animelists['my_score'] != 0]['my_score'].value_counts()\n",
    "(scores / scores.sum()).sort_index().plot(kind='bar', figsize=(16, 10), title='Rozdělení hodnocení')\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plt.xticks(rotation=0)\n",
    "plt.savefig('graphs/uzivatele-hodnoceni.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['all_meanscore'].plot(kind='hist', bins=100, figsize=(16, 10), title='Rozdělení průměru hodnocení podle uživatelů')\n",
    "plt.xticks(rotation=0)\n",
    "plt.savefig('graphs/uzivatele-hodnoceni-prumer-histogram.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total users:', users['all_meanscore'].count())\n",
    "print('users with mean score 10:', (users['all_meanscore'] == 10).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyzing users and genres now when I have features for genres per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_columns = sorted(['completed_'+x for x in genres])\n",
    "completed_columns.remove('completed_')  # removed empty genre\n",
    "users[completed_columns] = users[completed_columns].fillna(0)  # without this, NaN values are ommited from mean calculation, which messes up data a lot\n",
    "# semantically, NaN is zero, because it means that user has no completed anime of that genre\n",
    "users_completed = users[completed_columns].div(users['all_completed'], axis=0).fillna(0)\n",
    "users_ages_completed = users_completed.join(users['age'])\n",
    "ages_genres = users_ages_completed.groupby('age').mean()\n",
    "users_genders_completed = users_completed.join(users['gender'])\n",
    "genders_genres = users_genders_completed.groupby('gender').mean()\n",
    "\n",
    "above8_columns = sorted(['scoreabove8_'+x for x in genres])\n",
    "above8_columns.remove('scoreabove8_')  # removed empty genre\n",
    "above9_columns = sorted(['scoreabove9_'+x for x in genres])\n",
    "above9_columns.remove('scoreabove9_')  # removed empty genre\n",
    "users[above8_columns] = users[above8_columns].fillna(0)\n",
    "users[above9_columns] = users[above9_columns].fillna(0)\n",
    "mean_columns = sorted(['meanscore_'+x for x in genres])\n",
    "mean_columns.remove('meanscore_')  # removed empty genre\n",
    "users[mean_columns] = users[mean_columns].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try the histogram equalization on colormap to better show data\n",
    "# histogram equalization taken from https://github.com/jobar8/graphics/blob/master/graphics.py and modified little bit\n",
    "from skimage import exposure\n",
    "\n",
    "def cmap_to_array(cmap,N=256):\n",
    "    \"\"\"\n",
    "    Return a Nx3 array of RGB values generated from a colormap.\n",
    "    \"\"\"\n",
    "    return cmap(np.linspace(0, 1, N))[:,:3] # remove alpha column\n",
    "\n",
    "def equalize_colormap(cmap, data, name='EqualizedMap'):\n",
    "    if type(data) is pd.DataFrame:\n",
    "        data = data.as_matrix()\n",
    "    data = data[~np.isnan(data)].flatten()\n",
    "    cdf, bins = exposure.cumulative_distribution(data, nbins=256)\n",
    "    # Using it for highly non-uniform data will cause high information loss for extreme values\n",
    "    #So we do only half equalization, equalizing with histogram averaged with uniform histogram\n",
    "    # and now the same for uniform distribution of same size\n",
    "    cdf_u, bins_u = exposure.cumulative_distribution(np.linspace(data.min(), data.max(), data.shape[0]),nbins=256)\n",
    "    cdf = (cdf + cdf_u) / 2\n",
    "    '''\n",
    "    Re-map a colormap according to a cumulative distribution. This is used to \n",
    "    perform histogram equalization of an image by changing the colormap \n",
    "    instead of the image. *This is not strickly speaking the equalization of the \n",
    "    colormap itself*.\n",
    "    The cdf and bins should be calculated from an input image, as if carrying out\n",
    "    the histogram equalization of that image. In effect, the cdf becomes integrated  \n",
    "    to the colormap as a mapping function by redistributing the indices of the\n",
    "    input colormap.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cmap : string or colormap object\n",
    "        Input colormap to remap.\n",
    "    bins : array\n",
    "        Centers of bins.\n",
    "    cdf : array\n",
    "        Values of cumulative distribution function.\n",
    "    '''\n",
    "    \n",
    "    # first retrieve the color table (lists of RGB values) behind the input colormap\n",
    "    if cmap in mpl.cm.cmap_d: # matplotlib colormaps + plus the new ones (viridis, inferno, etc.)\n",
    "        cmList = cmap_to_array(cm.cmap_d[cmap])\n",
    "    else:\n",
    "        try:\n",
    "            # in case cmap is a colormap object\n",
    "            cmList = cmap_to_array(cmap) \n",
    "        except:\n",
    "            raise ValueError('Colormap {} has not been recognised'.format(cmap))\n",
    "    \n",
    "    # normalize the input bins to interval (0,1)\n",
    "    bins_norm = (bins - bins.min())/np.float(bins.max() - bins.min())\n",
    "    \n",
    "    # calculate new indices by applying the cdf as a function on the old indices\n",
    "    # which are initially regularly spaced. \n",
    "    old_indices = np.linspace(0,1,len(cmList))\n",
    "    new_indices = np.interp(old_indices,cdf,bins_norm)\n",
    "    \n",
    "    # make sure indices start with 0 and end with 1\n",
    "    new_indices[0] = 0.0\n",
    "    new_indices[-1] = 1.0\n",
    "    \n",
    "    # remap the color table\n",
    "    cdict = {'red': [], 'green': [], 'blue': []}\n",
    "    for i,n in enumerate(new_indices):\n",
    "        r1, g1, b1 = cmList[i]\n",
    "        cdict['red'].append([n, r1, r1])\n",
    "        cdict['green'].append([n, g1, g1])\n",
    "        cdict['blue'].append([n, b1, b1])\n",
    "        \n",
    "    return mpl.colors.LinearSegmentedColormap(name, cdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "#data = ages_genres.div(ages_genres.sum(axis=1), axis=0) * 100\n",
    "data = ages_genres * 100\n",
    "cmap = equalize_colormap(plt.cm.hot, data)\n",
    "mask = np.zeros_like(ages_genres, dtype=np.bool)\n",
    "mask[ages_genres == 0] = True\n",
    "sns.heatmap(data, mask=mask, cmap=cmap, linewidths=.5, cbar_kws={'format': '%.0f%%'})\n",
    "plt.title('genre percentage in animelists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "data = ages_genres.div(ages_genres.sum(axis=0), axis=1) * 100\n",
    "#data = ages_genres * 100\n",
    "mask = np.zeros_like(ages_genres, dtype=np.bool)\n",
    "mask[ages_genres == 0] = True\n",
    "sns.heatmap(data, mask=mask, cmap=plt.cm.hot, linewidths=.5, cbar_kws={'format': '%.0f%%'})\n",
    "plt.title('histograms normed per genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(18, 14))\n",
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "data = ages_genres.div(ages_genres.sum(axis=0), axis=1) * 100\n",
    "data = data.rename(columns=renaming)\n",
    "mask = np.zeros_like(ages_genres, dtype=np.bool)\n",
    "mask[ages_genres == 0] = True\n",
    "sns.heatmap(data, mask=mask, cmap=plt.cm.hot, linewidths=.5, cbar_kws={'format': '%.0f%%'})\n",
    "plt.title('Zastoupení anime s prvky v seznamu shlédnutých')\n",
    "plt.xticks(rotation=80)\n",
    "plt.ylabel('věk')\n",
    "plt.xlabel('prvky')\n",
    "plt.savefig('graphs/uzivatele-vek-zanr-heatmap.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[['all_completed', 'age', 'gender'] + completed_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in completed_columns:\n",
    "    sns.jointplot(x='age', y=genre, data=users_ages_completed, size=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='age', y='completed_Sci-Fi', data=users_ages_completed, size=16, kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='age', y='completed_Sci-Fi', data=users_ages_completed, size=16, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='age', y='completed_Sci-Fi', data=users_ages_completed, size=16, kind='resid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='age', y='completed_Sci-Fi', data=users_ages_completed, size=16, kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='age', y='completed_Sci-Fi', data=users_ages_completed, size=16, kind='hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.jointplot(x='age', y='completed_Sci-Fi', data=users_ages_completed, size=16).plot_joint(sns.kdeplot, zorder=0, n_levels=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy describes how many information it contains. Uniform distribution has highest entropy, dirac distribution lowest. \n",
    "# Lower entropy of genre means higher dependency on age\n",
    "ages_genres[completed_columns].apply(entropy).sort_values()\n",
    "# shows genres sorted by their dependency on age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.ones(ages_genres.index.size)\n",
    "entropy(arr / arr.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_genres = ages_genres[completed_columns].apply(entropy).sort_values().index[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(dependent_genres), 1, sharex=True, figsize=(16, 10))\n",
    "for i, genre in enumerate(dependent_genres):\n",
    "    ages_genres[genre].plot(kind='bar', ax=ax[i], title=genre.replace('completed_', ''))\n",
    "    ax[i].yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('věk')\n",
    "plt.savefig('graphs/uzivatele-vek-nejrozdilnejsi-bar.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders_genres.T.plot(kind='bar', figsize=(16, 10))\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda y, _: genders_genres.columns[y].replace('completed_', '')))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plt.title('Zastoupení anime s prvky v seznamu shlédnutých')\n",
    "plt.xticks(rotation=70)\n",
    "plt.ylabel('podíl ve shlédnutých')\n",
    "plt.xlabel('prvky')\n",
    "plt.savefig('graphs/uzivatele-pohlavi-bar.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genders_genres[completed_columns].apply(entropy).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genders_genres[completed_columns].apply(np.var).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.ones(genders_genres.index.size)\n",
    "entropy(arr / arr.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance is better than entropy now\n",
    "dependent_genres = genders_genres[completed_columns].apply(np.var).sort_values(ascending=False).index[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_num = np.ceil(np.sqrt(len(dependent_genres))).astype('int')\n",
    "#fig, ax = plt.subplots(sqrt_num, sqrt_num, figsize=(16, 10), squeeze=False)\n",
    "fig, ax = plt.subplots(4, 3, figsize=(16, 10), squeeze=False)\n",
    "ax = ax.flatten()\n",
    "for i, genre in enumerate(dependent_genres):\n",
    "    genders_genres[genre].plot(kind='barh', ax=ax[i], title=genre.replace('completed_', ''))\n",
    "    ax[i].xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
    "    ax[i].set_ylabel('')\n",
    "plt.tight_layout()\n",
    "#plt.subplots_adjust()\n",
    "#plt.xticks(rotation=70)\n",
    "plt.savefig('graphs/uzivatele-pohlavi-bar-jednotlive.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### and now binning ages into equi-sized bins\n",
    "age_bins, intervals = pd.qcut(users['age'], 10, retbins=True)\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins.value_counts()\n",
    "# these intervals suck, they fit 10-20 into one interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ages_completed['age'].value_counts().sort_index().plot(kind='bar', figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [9, 14, 17, 20, 23, 26, 30, 40, 50]\n",
    "pd.cut(users_ages_completed['age'], bins, right=True).value_counts()\n",
    "# hand-crafted by intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ages_completed['age_bin'] = pd.cut(users_ages_completed['age'], bins, right=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ages_completed['age_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_table(clf, target_column):\n",
    "    def expand_node(curr_node, prefix):\n",
    "        # three is balanced\n",
    "        thr_percent = \"{0:.1%}\".format(threshold[curr_node])\n",
    "        fname = fnames[feature[curr_node]]\n",
    "        if children_left[curr_node] == -1 and children_right[curr_node] == -1:\n",
    "            return [prefix], [targets[curr_node]], [value[curr_node, 0, :]]\n",
    "        l_res, l_target, l_distr = expand_node(children_left[curr_node], prefix + [fname + ' <= ' + thr_percent])\n",
    "        r_res, r_target, r_distr = expand_node(children_right[curr_node], prefix + [fname + ' > ' + thr_percent])\n",
    "        return l_res + r_res, l_target + r_target, l_distr + r_distr\n",
    "\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    feature = clf.tree_.feature\n",
    "    threshold = clf.tree_.threshold\n",
    "    value = clf.tree_.value\n",
    "\n",
    "    fnames = [i.replace('completed_', '') for i in completed_columns]\n",
    "    targets = [target_names[np.argmax(v)] for v in value]\n",
    "    paths, classes, distr = expand_node(0, [])\n",
    "    distr = np.array(distr)\n",
    "    indices = pd.MultiIndex.from_tuples(paths)\n",
    "    df = pd.DataFrame({target_column: classes, 'precision': (distr.max(axis=1) / distr.sum(axis=1))},\n",
    "                      index=indices)\n",
    "    df['precision'] = df['precision'].apply(lambda x: \"{0:.2f}%\".format(x * 100))\n",
    "    # precision in classification terminology is # correctly classified / # totally classified (correctly + incorrectly)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing gender based on completed genres histogram\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf, out_file='gender_classifier.dot',\n",
    "                         feature_names=[i.replace('completed_', '') for i in completed_columns],\n",
    "                         class_names=users_genders_completed['gender'].unique(),\n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                         feature_names=[i.replace('completed_', '') for i in completed_columns],\n",
    "                         class_names=users_genders_completed['gender'].unique(),\n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_to_table(clf, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing precision depending on depth\n",
    "clf = tree.DecisionTreeClassifier(max_depth=1)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing precision depending on depth\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tree_clf.rick', 'wb+') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=4)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                         feature_names=[i.replace('completed_', '') for i in completed_columns],\n",
    "                         class_names=users_genders_completed['gender'].unique(),\n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=6)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=7)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=8)\n",
    "clf = clf.fit(users_genders_completed[completed_columns], users_genders_completed['gender'])\n",
    "y_true = users_genders_completed['gender']\n",
    "y_pred = clf.predict(users_genders_completed[completed_columns])\n",
    "target_names = users_genders_completed['gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, trying some depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=4)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=6)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=7)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=8)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=9)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=10)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 depth seems like nice tradeoff based \n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(users_ages_completed[completed_columns], users_ages_completed['age_bin'])\n",
    "y_true = users_ages_completed['age_bin']\n",
    "y_pred = clf.predict(users_ages_completed[completed_columns])\n",
    "target_names = users_ages_completed['age_bin'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf, out_file='age_classifier.dot',\n",
    "                         feature_names=[i.replace('completed_', '') for i in completed_columns],\n",
    "                         class_names=users_ages_completed['age_bin'].unique(),\n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                         feature_names=[i.replace('completed_', '') for i in completed_columns],\n",
    "                         class_names=users_ages_completed['age_bin'].unique(),\n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tree_to_table(clf, 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genres in completed animests, compared with genres production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animes['genres'].fillna('', inplace=True)\n",
    "genres_arr = animes['genres'].apply(lambda x: x.replace(' ', '').split(',')).apply(pd.Series).stack().to_frame(name='genre')\n",
    "genres_arr = genres_arr[genres_arr['genre'] != '']\n",
    "genres_arr.index.levels[0].name = 'anime_id'\n",
    "animes_genres = pd.merge(animes, genres_arr, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(animes_genres['genre'].value_counts() / animes.shape[0]).sort_index().plot(kind='bar', figsize=(16, 10))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "users[completed_columns].rename(columns=renaming).div(users['all_completed'], axis=0).mean().sort_index().plot(kind='bar', figsize=(16, 10))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "users[completed_columns].rename(columns=renaming).div(users['all_completed'], axis=0).mean().sort_index().plot(kind='bar', figsize=(16, 10))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plt.title('Poměr prvků v seznamu shlednutých')\n",
    "plt.xticks(rotation=70)\n",
    "plt.ylabel('podíl ve shlédnutých')\n",
    "plt.xlabel('prvky')\n",
    "plt.savefig('graphs/uzivatele-shlednute-genres.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "anime_genres_percent = (animes_genres['genre'].value_counts() / animes.shape[0]).sort_index()\n",
    "anime_genres_percent.plot(kind='bar', figsize=(16, 10), title='Rozdíl zastoupení prvků v produkci a ve shlédnutých titulech', color='blue', alpha=0.5, label='Zastoupení prvku v celkové produkci')\n",
    "users_genres_percent = users[completed_columns].rename(columns=renaming).div(users['all_completed'], axis=0).mean().sort_index()\n",
    "users_genres_percent.plot(kind='bar', color='red', alpha=0.5, label='Zastoupení prvku ve shlednutých titulech')\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "plt.legend(loc=1)\n",
    "plt.xticks(rotation=70)\n",
    "plt.ylabel('zastoupení')\n",
    "plt.xlabel('prvky')\n",
    "plt.savefig('graphs/uzivatele-shlednute-genres-comparison.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new classes for users, both gender and age bin will be class, will try whether decision trees will have bigger success\n",
    "users_ages_genders_completed = users_ages_completed.join(users_genders_completed['gender'])\n",
    "users_ages_genders_completed['age_and_gender'] = users_ages_genders_completed['age_bin'] + ', ' + users_ages_genders_completed['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf = clf.fit(users_ages_genders_completed[completed_columns], users_ages_genders_completed['age_and_gender'])\n",
    "y_true = users_ages_genders_completed['age_and_gender']\n",
    "y_pred = clf.predict(users_ages_genders_completed[completed_columns])\n",
    "target_names = users_ages_genders_completed['age_and_gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender and age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf = clf.fit(users_ages_genders_completed[completed_columns], users_ages_genders_completed['age_and_gender'])\n",
    "y_true = users_ages_genders_completed['age_and_gender']\n",
    "y_pred = clf.predict(users_ages_genders_completed[completed_columns])\n",
    "target_names = users_ages_genders_completed['age_and_gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender and age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=4)\n",
    "clf = clf.fit(users_ages_genders_completed[completed_columns], users_ages_genders_completed['age_and_gender'])\n",
    "y_true = users_ages_genders_completed['age_and_gender']\n",
    "y_pred = clf.predict(users_ages_genders_completed[completed_columns])\n",
    "target_names = users_ages_genders_completed['age_and_gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender and age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(users_ages_genders_completed[completed_columns], users_ages_genders_completed['age_and_gender'])\n",
    "y_true = users_ages_genders_completed['age_and_gender']\n",
    "y_pred = clf.predict(users_ages_genders_completed[completed_columns])\n",
    "target_names = users_ages_genders_completed['age_and_gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender and age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                         feature_names=[i.replace('completed_', '') for i in completed_columns],\n",
    "                         class_names=users_ages_genders_completed['age_and_gender'].unique(),\n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=6)\n",
    "clf = clf.fit(users_ages_genders_completed[completed_columns], users_ages_genders_completed['age_and_gender'])\n",
    "y_true = users_ages_genders_completed['age_and_gender']\n",
    "y_pred = clf.predict(users_ages_genders_completed[completed_columns])\n",
    "target_names = users_ages_genders_completed['age_and_gender'].unique()\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "tree_to_table(clf, 'gender and age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nothing interesting in decision trees above, gender does not bring precision into age prediction\n",
    "### going to measure genre distances by users animelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# doing PCA on genres distribution\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "\n",
    "pca = decomposition.PCA(n_components=3)\n",
    "embeddings = pca.fit_transform(users_ages_genders_completed[completed_columns])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# colors per gender\n",
    "ax = plt.axes(projection='3d')\n",
    "le = preprocessing.LabelEncoder()\n",
    "genders = le.fit_transform(users_ages_genders_completed['gender'])\n",
    "genders = genders.astype(np.int)\n",
    "colors = plt.cm.Set1(np.unique(genders))\n",
    "ax.scatter3D(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2], s=1, c=[colors[x] for x in genders])\n",
    "plt.title(\"users by genres in 3D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsd(x, y):\n",
    "    return (max(np.log(x.sum()), np.log(y.sum())) - np.log((x & y).sum())) / (np.log(x.size) - min(np.log(x.sum()), np.log(y.sum())))\n",
    "\n",
    "# todo: vymyslet co s tím, když je to spojité a ne binární\n",
    "%matplotlib inline\n",
    "\n",
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "dists = pdist(users_completed[completed_columns].rename(columns=renaming).T > 0, lambda x, y: nsd(x, y))\n",
    "dists_m = squareform(dists)\n",
    "dists_m[dists_m == np.inf] = 0  # infinities mess color scale\n",
    "\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = users_completed.T.index\n",
    "dists_df.index = users_completed.T.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "mask = np.zeros_like(dists_df, dtype=np.bool)\n",
    "mask[dists_df == 0] = True\n",
    "sns.heatmap(dists_df, mask=mask, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "genres_users = users_completed[completed_columns].rename(columns=renaming).T\n",
    "dists = pdist(genres_users, 'cosine')\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = manifold.MDS(2, max_iter=2000, n_init=5, dissimilarity='precomputed')\n",
    "embeddings = embedder.fit_transform(dists_m)\n",
    "# need to agregate animes_studios because it does not contain duplicities because of genres\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
    "plt.title(\"genres by users similar completed\")\n",
    "texts = [plt.text(embeddings[i, 0], embeddings[i, 1], txt) for i, txt in enumerate(dists_df.index)]\n",
    "adjust_text(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "embedder = manifold.MDS(2, max_iter=2000, n_init=5, dissimilarity='precomputed')\n",
    "embeddings = embedder.fit_transform(dists_m)\n",
    "\n",
    "kmeans = KMeans(init='k-means++', n_clusters=21, n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .002     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = embeddings[:, 0].min() - 0.1, embeddings[:, 0].max() + 0.1\n",
    "y_min, y_max = embeddings[:, 1].min() - 0.1, embeddings[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.tab20,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
    "#plt.plot(embeddings[:, 0], embeddings[:, 1], 'k.', markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "plt.title('K-means clustering on genres based on users')\n",
    "\n",
    "texts = [plt.text(embeddings[i, 0], embeddings[i, 1], txt) for i, txt in enumerate(dists_df.index)]\n",
    "adjust_text(texts)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# generate the linkage matrix \n",
    "# squareform transfers between condensed and redundant distance form\n",
    "Z = linkage(squareform(dists_m), 'ward')\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "#    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=12.,  # font size for the x axis labels\n",
    "    orientation='right',\n",
    "    labels=dists_df.index\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now with thresholding, more than 0.9 dissimilarity is undefined\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "dists = pdist(genres_users, 'cosine')\n",
    "dists_m = squareform(dists)\n",
    "dists_m[dists_m > 0.9] = 0\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "mask = np.zeros_like(dists_df, dtype=np.bool)\n",
    "mask[dists_df == 0] = True\n",
    "\n",
    "sns.heatmap(dists_df, mask=mask, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(sizes):\n",
    "    def my_init():\n",
    "        ax.scatter3D(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2], s=sizes)\n",
    "        return fig,\n",
    "    return my_init\n",
    "\n",
    "def animate(i):\n",
    "    ax.azim = ax.azim - 2\n",
    "    ax.view_init(ax.elev, ax.azim)\n",
    "    return fig,\n",
    "\n",
    "def points_3d_to_gif(embeddings, labels, gif_filename, ax, sizes):\n",
    "    for i, txt in enumerate(labels):\n",
    "        ax.text(embeddings[i, 0], embeddings[i, 1], embeddings[i, 2], txt)\n",
    "\n",
    "    #plt.axis('off')\n",
    "    #ax.grid(False)\n",
    "    ax.grid(True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    ax.elev = 25.\n",
    "    ax.azim = 321.\n",
    "    ax.dist = 11.\n",
    "\n",
    "    # Animate, interval in ms, frames == # of frames in animation\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init(sizes),\n",
    "                                   frames=180, interval=80, blit=True)\n",
    "    # Save\n",
    "    anim.save('images/{}.gif'.format(gif_filename), dpi=80, writer='imagemagick')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = pdist(genres_users, 'cosine')\n",
    "dists_m = squareform(dists)\n",
    "dists_m[dists_m > 0.9] = 0  # I need to set infinities to zeros, then it handles infinities as missing data, which is wanted\n",
    "embedder = manifold.MDS(3, metric=False, max_iter=2000, n_init=10, dissimilarity='precomputed')\n",
    "embeddings = embedder.fit_transform(dists_m)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "plt.title(\"genres by users in 3D\")\n",
    "points_3d_to_gif(embeddings, genres_users.index, 'genres_users-cosine-MSD', ax, genres_users.sum(axis=1).apply(np.log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.array(list(combinations(genres_users.index, 2)))\n",
    "\n",
    "# for gephi, higher edge cost means higher similarity\n",
    "edges = pd.DataFrame({'source': pairs[:, 0], 'target': pairs[:, 1], 'weight': 1-dists})\n",
    "edges = edges[edges['weight'] != np.inf]\n",
    "\n",
    "nodes = pd.DataFrame({'id': genres_users.index, 'label': genres_users.index})\n",
    "edges['type'] = 'undirected'\n",
    "\n",
    "nodes.to_csv('genres_users_nodes.csv', index=False, sep=',', encoding='utf-8')\n",
    "edges.to_csv('genres_users_edges_cosine.csv', index=False, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "genres_users = users_completed[completed_columns].rename(columns=renaming).T\n",
    "dists = pdist(genres_users, 'euclidean')\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "genres_users = users_completed[completed_columns].rename(columns=renaming).T\n",
    "dists = pdist(genres_users, 'cityblock')\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "genres_users = users_completed[completed_columns].rename(columns=renaming).T\n",
    "dists = pdist(genres_users, 'canberra')\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Jensen Shannon diverge, which is symeterized version of KL divergence\n",
    "def js(p, q):\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "    m = (p + q) / 2\n",
    "    return (entropy(p, m) + entropy(q, m)) / 2\n",
    "\n",
    "def js_metric(p, q):\n",
    "    # with square root it will satisfy triangle inequality\n",
    "    return np.sqrt(js(p, q))\n",
    "\n",
    "renaming = {x: x.replace('completed_', '') for x in completed_columns}\n",
    "genres_users = users_completed[completed_columns].rename(columns=renaming).T\n",
    "dists = pdist(genres_users, lambda x, y: js_metric(x, y))\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "mask = np.zeros_like(dists_df, dtype=np.bool)\n",
    "mask[(1-dists_df) < 0.5] = True\n",
    "\n",
    "sns.heatmap(1-dists_df, mask=mask, linewidths=.5, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(dists_df, dtype=np.bool)\n",
    "mask[dists_df == 0] = True\n",
    "\n",
    "dists_df_inv = 1 / dists_df\n",
    "dists_df_inv[dists_df_inv == np.inf] = 0\n",
    "mask[dists_df_inv < 2] = True  # inspect how filtering low similarities will look like\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df_inv, mask=mask, linewidths=.5, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('scoreabove8_', '') for x in above8_columns}\n",
    "genres_users = users[above8_columns].rename(columns=renaming).T\n",
    "dists = pdist(genres_users, 'cosine')\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "mask = np.zeros_like(dists_df, dtype=np.bool)\n",
    "mask[dists_df  > 0.5] = True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df, mask=mask, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('scoreabove9_', '') for x in above9_columns}\n",
    "genres_users = users[above9_columns].rename(columns=renaming).T\n",
    "dists = pdist(genres_users, 'cosine')\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming = {x: x.replace('scoreabove9_', '') for x in above9_columns}\n",
    "genres_users = users[above9_columns].div(users['all_rated'], axis=0).fillna(0).rename(columns=renaming).T\n",
    "dists = pdist(genres_users, 'cosine')\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df, linewidths=.5, cmap=plt.cm.hot_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSD on 9 or more mean score\n",
    "def nsd(x, y):\n",
    "    return (max(np.log(x.sum()), np.log(y.sum())) - np.log((x & y).sum())) / (np.log(x.size) - min(np.log(x.sum()), np.log(y.sum())))\n",
    "\n",
    "renaming = {x: x.replace('meanscore_', '') for x in mean_columns}\n",
    "genres_users = (users[mean_columns] >= 9).rename(columns=renaming).T\n",
    "dists = pdist(genres_users, lambda x, y: nsd(x, y))\n",
    "dists_m = squareform(dists)\n",
    "dists_df = pd.DataFrame(dists_m)\n",
    "dists_df.columns = genres_users.index\n",
    "dists_df.index = genres_users.index\n",
    "\n",
    "f, ax = plt.subplots(figsize=(18, 14))\n",
    "sns.heatmap(dists_df, linewidths=.5, cmap=plt.cm.hot_r)\n",
    "\n",
    "plt.title('vzdálenost žánrů podle kladně hodnotících uživatelů')\n",
    "plt.xticks(rotation=80)\n",
    "plt.ylabel('zastoupení')\n",
    "plt.xlabel('prvky')\n",
    "plt.savefig('graphs/uzivatele-zanry-9-a-vice-heatmap.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(dists_df, dtype=np.bool)\n",
    "mask[dists_df == 0] = True\n",
    "\n",
    "dists_df_inv = 1 / dists_df\n",
    "dists_df_inv[dists_df_inv == np.inf] = 0\n",
    "mask[dists_df_inv < 1.6] = True  # inspect how filtering low similarities will look like\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 10))\n",
    "sns.heatmap(dists_df_inv, mask=mask, linewidths=.5, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDS embedding for NSD\n",
    "embedder = manifold.MDS(2, max_iter=2000, n_init=5, dissimilarity='precomputed')\n",
    "embeddings = embedder.fit_transform(dists_m)\n",
    "# need to agregate animes_studios because it does not contain duplicities because of genres\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
    "plt.title(\"genres by users similar completed\")\n",
    "texts = [plt.text(embeddings[i, 0], embeddings[i, 1], txt) for i, txt in enumerate(dists_df.index)]\n",
    "adjust_text(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "embedder = manifold.MDS(2, max_iter=2000, n_init=5, dissimilarity='precomputed')\n",
    "embeddings = embedder.fit_transform(dists_m)\n",
    "\n",
    "kmeans = KMeans(init='k-means++', n_clusters=21, n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .002     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = embeddings[:, 0].min() - 0.1, embeddings[:, 0].max() + 0.1\n",
    "y_min, y_max = embeddings[:, 1].min() - 0.1, embeddings[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.tab20,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
    "#plt.plot(embeddings[:, 0], embeddings[:, 1], 'k.', markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "plt.title('K-means clustering on genres based on users')\n",
    "\n",
    "texts = [plt.text(embeddings[i, 0], embeddings[i, 1], txt) for i, txt in enumerate(dists_df.index)]\n",
    "adjust_text(texts)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# generate the linkage matrix \n",
    "# squareform transfers between condensed and redundant distance form\n",
    "Z = linkage(squareform(dists_m), 'ward')\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "#    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=12.,  # font size for the x axis labels\n",
    "    orientation='right',\n",
    "    labels=dists_df.index\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.array(list(combinations(genres_users.index, 2)))\n",
    "\n",
    "\n",
    "# for gephi, higher edge cost means higher similarity\n",
    "edges = pd.DataFrame({'source': pairs[:, 0], 'target': pairs[:, 1], 'weight': 1/dists})\n",
    "edges = edges[edges['weight'] != np.inf]\n",
    "\n",
    "nodes = pd.DataFrame({'id': genres_users.index, 'label': genres_users.index})\n",
    "edges['type'] = 'undirected'\n",
    "\n",
    "nodes.to_csv('genres_users_nodes.csv', index=False, sep=',', encoding='utf-8')\n",
    "edges.to_csv('genres_users_edges_NSD.csv', index=False, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
